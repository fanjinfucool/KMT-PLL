# KMT-PLL

This is the code for the paper: KMT-PLL: K-Means Cross-Attention Transformer for Partial Label Learning


To be presented at IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS.

## Setups

All code was developed and tested on a single machine equiped with a NVIDIA GeForce RTX 4060 GPU. The environment is as bellow:
- Python 3.6.8
- Numpy 1.16.4
- Cuda 10.1.168

## Quick Start

Here is an example:
```
python main.py
```
```
python train.py
```

## Results

The test results and transductive accuracy are printed in result/ by default.

Contact: (fan_jinfu@163.com).
